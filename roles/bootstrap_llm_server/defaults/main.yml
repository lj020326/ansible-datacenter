---
# User Configuration
bootstrap_llm_server__ollama_user: ollama
bootstrap_llm_server__webui_user: webui

# Service Configuration
bootstrap_llm_server__ollama_port: "11434"
bootstrap_llm_server__webui_port: "8080"
bootstrap_llm_server__nginx_port: "80"

# Model Configuration
bootstrap_llm_server__deepseek_models:
  - deepseek-coder:6.7b
  - deepseek-coder:1.3b
  - deepseek-llm:7b

bootstrap_llm_server__additional_models:
  - llama3.2:3b
  - mistral:7b

# Feature Flags
bootstrap_llm_server__install_nvidia: true
bootstrap_llm_server__install_open_webui: true
bootstrap_llm_server__install_ollama_webui: false
bootstrap_llm_server__configure_nginx: true
bootstrap_llm_server__configure_firewall: true
bootstrap_llm_server__download_models: true

# Paths
bootstrap_llm_server__ollama_home: /home/{{ bootstrap_llm_server__ollama_user }}
bootstrap_llm_server__webui_home: /home/{{ bootstrap_llm_server__webui_user }}

# Timeout Configuration
bootstrap_llm_server__model_download_timeout: 3600
bootstrap_llm_server__service_timeout: 300

# System packages required
bootstrap_llm_server__system_packages:
  - curl
  - wget
  - git
  - python3
  - python3-pip
  - python3-venv
  - nodejs
  - npm
  - nginx
  - ufw
  - htop
  - nvtop
  - build-essential

# NVIDIA packages
#bootstrap_llm_server__nvidia_packages:
#  - nvidia-driver-535
#  - cuda-toolkit-12-2
#
#bootstrap_llm_server__nvidia_packages:
#  - nvidia-driver-570-open
#  - cuda-toolkit-12-12

bootstrap_llm_server__nvidia_package_dist: "{{ ansible_distribution | lower }}{{ ansible_distribution_version | replace('.','') }}"

#bootstrap_llm_server__nvidia_package_version: "1.0-1"
bootstrap_llm_server__nvidia_package_version: 1.1-1

bootstrap_llm_server__nvidia_package: cuda-keyring_{{ bootstrap_llm_server__nvidia_package_version }}_all.deb

bootstrap_llm_server__nvidia_package_url: https://developer.download.nvidia.com/compute/cuda/repos/{{ bootstrap_llm_server__nvidia_package_dist }}/x86_64/{{ bootstrap_llm_server__nvidia_package
  }}
